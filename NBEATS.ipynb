{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wTvqp5JpiwM",
        "outputId": "87fc97d4-a10e-49a4-e839-8761b989f85f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKtEPtFlpeS8",
        "outputId": "545805c9-2218-4e91-e8e5-5c728e38f4bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: NBEATS in /usr/local/lib/python3.9/dist-packages (1.3.11)\n",
            "Requirement already satisfied: nbeats-pytorch in /usr/local/lib/python3.9/dist-packages (from NBEATS) (1.8.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from nbeats-pytorch->NBEATS) (1.4.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from nbeats-pytorch->NBEATS) (3.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from nbeats-pytorch->NBEATS) (2.0.0+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from nbeats-pytorch->NBEATS) (1.22.4)\n",
            "Requirement already satisfied: keract in /usr/local/lib/python3.9/dist-packages (from nbeats-pytorch->NBEATS) (4.5.1)\n",
            "Requirement already satisfied: protobuf<=3.20 in /usr/local/lib/python3.9/dist-packages (from nbeats-pytorch->NBEATS) (3.20.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->nbeats-pytorch->NBEATS) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->nbeats-pytorch->NBEATS) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->nbeats-pytorch->NBEATS) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->nbeats-pytorch->NBEATS) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->nbeats-pytorch->NBEATS) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->nbeats-pytorch->NBEATS) (23.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->nbeats-pytorch->NBEATS) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->nbeats-pytorch->NBEATS) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->nbeats-pytorch->NBEATS) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->nbeats-pytorch->NBEATS) (2022.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->nbeats-pytorch->NBEATS) (3.10.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->nbeats-pytorch->NBEATS) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->nbeats-pytorch->NBEATS) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->nbeats-pytorch->NBEATS) (3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->nbeats-pytorch->NBEATS) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->nbeats-pytorch->NBEATS) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->nbeats-pytorch->NBEATS) (16.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->nbeats-pytorch->NBEATS) (3.25.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->nbeats-pytorch->NBEATS) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->nbeats-pytorch->NBEATS) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->nbeats-pytorch->NBEATS) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->nbeats-pytorch->NBEATS) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install NBEATS"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from NBEATS import NeuralBeats\n",
        "from torch import optim\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "HeCesdaFp126"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/new/datasets/sri_lanka.csv\", usecols=[\"Inflation Rate\"])\n",
        "data.transpose()\n",
        "data = data.values"
      ],
      "metadata": {
        "id": "Vwk5hHYcpxif"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=NeuralBeats(data=data,forecast_length=6,stack=[1,3],nb_blocks_per_stack=3,thetas_dims=[3,7])\n",
        "model.fit(epoch=50,optimiser=optim.AdamW(model.parameters, lr=0.001, betas=(0.9, 0.999), eps=1e-07, weight_decay=0.01, amsgrad=False),plot=False, verbose=True)\n",
        "forecast=model.predict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srealZxepujM",
        "outputId": "2cea0f9f-c796-4373-c595-99bea39f04e3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| N-Beats\n",
            "| --  Stack Generic (#0) (share_weights_in_stack=False)\n",
            "     | -- GenericBlock(units=128, thetas_dim=3, backcast_length=18, forecast_length=6, share_thetas=False) at @139736458195296\n",
            "     | -- GenericBlock(units=128, thetas_dim=3, backcast_length=18, forecast_length=6, share_thetas=False) at @139736458195536\n",
            "     | -- GenericBlock(units=128, thetas_dim=3, backcast_length=18, forecast_length=6, share_thetas=False) at @139736458616640\n",
            "| --  Stack Seasonality (#1) (share_weights_in_stack=False)\n",
            "     | -- SeasonalityBlock(units=128, thetas_dim=6, backcast_length=18, forecast_length=6, share_thetas=True) at @139736458198992\n",
            "     | -- SeasonalityBlock(units=128, thetas_dim=6, backcast_length=18, forecast_length=6, share_thetas=True) at @139736458615680\n",
            "     | -- SeasonalityBlock(units=128, thetas_dim=6, backcast_length=18, forecast_length=6, share_thetas=True) at @139736458614816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/NBEATS/model.py:86: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  s1 = torch.tensor([np.cos(2 * np.pi * i * t) for i in range(p1)]).float()  # H/2-1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "grad_step = 000030, tr_loss = 0.092962, te_loss = 0.796638\n",
            "grad_step = 000060, tr_loss = 0.039461, te_loss = 0.796638\n",
            "grad_step = 000090, tr_loss = 0.007856, te_loss = 0.796638\n",
            "grad_step = 000120, tr_loss = 0.000770, te_loss = 0.005407\n",
            "grad_step = 000150, tr_loss = 0.000168, te_loss = 0.005407\n",
            "grad_step = 000180, tr_loss = 0.000094, te_loss = 0.005407\n",
            "grad_step = 000210, tr_loss = 0.000407, te_loss = 0.001970\n",
            "grad_step = 000240, tr_loss = 0.000107, te_loss = 0.001970\n",
            "grad_step = 000270, tr_loss = 0.000062, te_loss = 0.001970\n",
            "grad_step = 000300, tr_loss = 0.000336, te_loss = 0.001970\n",
            "grad_step = 000330, tr_loss = 0.000050, te_loss = 0.002142\n",
            "grad_step = 000360, tr_loss = 0.000048, te_loss = 0.002142\n",
            "grad_step = 000390, tr_loss = 0.000050, te_loss = 0.002142\n",
            "grad_step = 000420, tr_loss = 0.000035, te_loss = 0.002494\n",
            "grad_step = 000450, tr_loss = 0.000239, te_loss = 0.002494\n",
            "grad_step = 000480, tr_loss = 0.000033, te_loss = 0.002494\n",
            "grad_step = 000510, tr_loss = 0.000020, te_loss = 0.002218\n",
            "grad_step = 000540, tr_loss = 0.000016, te_loss = 0.002218\n",
            "grad_step = 000570, tr_loss = 0.000486, te_loss = 0.002218\n",
            "grad_step = 000600, tr_loss = 0.000049, te_loss = 0.002218\n",
            "grad_step = 000630, tr_loss = 0.000012, te_loss = 0.002394\n",
            "grad_step = 000660, tr_loss = 0.000009, te_loss = 0.002394\n",
            "grad_step = 000690, tr_loss = 0.000007, te_loss = 0.002394\n",
            "grad_step = 000720, tr_loss = 0.000006, te_loss = 0.002071\n",
            "grad_step = 000750, tr_loss = 0.000019, te_loss = 0.002071\n",
            "grad_step = 000780, tr_loss = 0.000133, te_loss = 0.002071\n",
            "grad_step = 000810, tr_loss = 0.000006, te_loss = 0.002037\n",
            "grad_step = 000840, tr_loss = 0.000003, te_loss = 0.002037\n",
            "grad_step = 000870, tr_loss = 0.000002, te_loss = 0.002037\n",
            "grad_step = 000900, tr_loss = 0.000002, te_loss = 0.002037\n",
            "grad_step = 000930, tr_loss = 0.000002, te_loss = 0.001944\n",
            "grad_step = 000960, tr_loss = 0.000834, te_loss = 0.001944\n",
            "grad_step = 000990, tr_loss = 0.000013, te_loss = 0.001944\n",
            "grad_step = 001020, tr_loss = 0.000002, te_loss = 0.001964\n",
            "grad_step = 001050, tr_loss = 0.000001, te_loss = 0.001964\n",
            "grad_step = 001080, tr_loss = 0.000009, te_loss = 0.001964\n",
            "grad_step = 001110, tr_loss = 0.000036, te_loss = 0.002071\n",
            "grad_step = 001140, tr_loss = 0.000113, te_loss = 0.002071\n",
            "grad_step = 001170, tr_loss = 0.000017, te_loss = 0.002071\n",
            "grad_step = 001200, tr_loss = 0.000001, te_loss = 0.002071\n",
            "grad_step = 001230, tr_loss = 0.000027, te_loss = 0.001910\n",
            "grad_step = 001260, tr_loss = 0.000070, te_loss = 0.001910\n",
            "grad_step = 001290, tr_loss = 0.000004, te_loss = 0.001910\n",
            "grad_step = 001320, tr_loss = 0.000001, te_loss = 0.001921\n",
            "grad_step = 001350, tr_loss = 0.000001, te_loss = 0.001921\n",
            "grad_step = 001380, tr_loss = 0.000001, te_loss = 0.001921\n",
            "grad_step = 001410, tr_loss = 0.000001, te_loss = 0.001934\n",
            "grad_step = 001440, tr_loss = 0.000008, te_loss = 0.001934\n",
            "grad_step = 001470, tr_loss = 0.000015, te_loss = 0.001934\n",
            "grad_step = 001500, tr_loss = 0.000001, te_loss = 0.001934\n",
            "grad_step = 001530, tr_loss = 0.000001, te_loss = 0.001924\n",
            "grad_step = 001560, tr_loss = 0.000001, te_loss = 0.001924\n",
            "grad_step = 001590, tr_loss = 0.000000, te_loss = 0.001924\n",
            "grad_step = 001620, tr_loss = 0.000231, te_loss = 0.001963\n",
            "grad_step = 001650, tr_loss = 0.000027, te_loss = 0.001963\n",
            "grad_step = 001680, tr_loss = 0.000001, te_loss = 0.001963\n",
            "grad_step = 001710, tr_loss = 0.000000, te_loss = 0.001941\n",
            "grad_step = 001740, tr_loss = 0.000000, te_loss = 0.001941\n",
            "grad_step = 001770, tr_loss = 0.000000, te_loss = 0.001941\n",
            "grad_step = 001800, tr_loss = 0.000000, te_loss = 0.001941\n",
            "grad_step = 001830, tr_loss = 0.001227, te_loss = 0.001965\n",
            "grad_step = 001860, tr_loss = 0.000042, te_loss = 0.001965\n",
            "grad_step = 001890, tr_loss = 0.000002, te_loss = 0.001965\n",
            "grad_step = 001920, tr_loss = 0.000000, te_loss = 0.002007\n",
            "grad_step = 001950, tr_loss = 0.000000, te_loss = 0.002007\n",
            "grad_step = 001980, tr_loss = 0.000000, te_loss = 0.002007\n",
            "grad_step = 002010, tr_loss = 0.000000, te_loss = 0.002034\n",
            "grad_step = 002040, tr_loss = 0.000000, te_loss = 0.002034\n",
            "grad_step = 002070, tr_loss = 0.000000, te_loss = 0.002034\n",
            "grad_step = 002100, tr_loss = 0.000000, te_loss = 0.002034\n",
            "grad_step = 002130, tr_loss = 0.000000, te_loss = 0.002037\n",
            "grad_step = 002160, tr_loss = 0.000013, te_loss = 0.002037\n",
            "grad_step = 002190, tr_loss = 0.000064, te_loss = 0.002037\n",
            "grad_step = 002220, tr_loss = 0.000003, te_loss = 0.002113\n",
            "grad_step = 002250, tr_loss = 0.000000, te_loss = 0.002113\n",
            "grad_step = 002280, tr_loss = 0.000000, te_loss = 0.002113\n",
            "grad_step = 002310, tr_loss = 0.000000, te_loss = 0.002042\n",
            "grad_step = 002340, tr_loss = 0.000000, te_loss = 0.002042\n",
            "grad_step = 002370, tr_loss = 0.000000, te_loss = 0.002042\n",
            "grad_step = 002400, tr_loss = 0.000125, te_loss = 0.002042\n",
            "grad_step = 002430, tr_loss = 0.000067, te_loss = 0.001947\n",
            "grad_step = 002460, tr_loss = 0.000003, te_loss = 0.001947\n",
            "grad_step = 002490, tr_loss = 0.000000, te_loss = 0.001947\n",
            "grad_step = 002520, tr_loss = 0.000000, te_loss = 0.002088\n",
            "grad_step = 002550, tr_loss = 0.000000, te_loss = 0.002088\n",
            "grad_step = 002580, tr_loss = 0.000000, te_loss = 0.002088\n",
            "grad_step = 002610, tr_loss = 0.000000, te_loss = 0.002097\n",
            "grad_step = 002640, tr_loss = 0.000000, te_loss = 0.002097\n",
            "grad_step = 002670, tr_loss = 0.000000, te_loss = 0.002097\n",
            "grad_step = 002700, tr_loss = 0.000000, te_loss = 0.002097\n",
            "grad_step = 002730, tr_loss = 0.000117, te_loss = 0.002101\n",
            "grad_step = 002760, tr_loss = 0.000013, te_loss = 0.002101\n",
            "grad_step = 002790, tr_loss = 0.000001, te_loss = 0.002101\n",
            "grad_step = 002820, tr_loss = 0.000000, te_loss = 0.002147\n",
            "grad_step = 002850, tr_loss = 0.000000, te_loss = 0.002147\n",
            "grad_step = 002880, tr_loss = 0.000007, te_loss = 0.002147\n",
            "grad_step = 002910, tr_loss = 0.000007, te_loss = 0.002139\n",
            "grad_step = 002940, tr_loss = 0.000001, te_loss = 0.002139\n",
            "grad_step = 002970, tr_loss = 0.000000, te_loss = 0.002139\n",
            "grad_step = 003000, tr_loss = 0.000000, te_loss = 0.002139\n",
            "grad_step = 003030, tr_loss = 0.000000, te_loss = 0.002178\n",
            "grad_step = 003060, tr_loss = 0.000001, te_loss = 0.002178\n",
            "grad_step = 003090, tr_loss = 0.000208, te_loss = 0.002178\n",
            "grad_step = 003120, tr_loss = 0.000006, te_loss = 0.002187\n",
            "grad_step = 003150, tr_loss = 0.000000, te_loss = 0.002187\n",
            "grad_step = 003180, tr_loss = 0.000000, te_loss = 0.002187\n",
            "grad_step = 003210, tr_loss = 0.000000, te_loss = 0.002306\n",
            "grad_step = 003240, tr_loss = 0.000000, te_loss = 0.002306\n",
            "grad_step = 003270, tr_loss = 0.000000, te_loss = 0.002306\n",
            "grad_step = 003300, tr_loss = 0.000000, te_loss = 0.002306\n",
            "grad_step = 003330, tr_loss = 0.000000, te_loss = 0.002311\n",
            "grad_step = 003360, tr_loss = 0.000000, te_loss = 0.002311\n",
            "grad_step = 003390, tr_loss = 0.000000, te_loss = 0.002311\n",
            "grad_step = 003420, tr_loss = 0.000000, te_loss = 0.002314\n",
            "grad_step = 003450, tr_loss = 0.000000, te_loss = 0.002314\n",
            "grad_step = 003480, tr_loss = 0.000002, te_loss = 0.002314\n",
            "grad_step = 003510, tr_loss = 0.000013, te_loss = 0.002118\n",
            "grad_step = 003540, tr_loss = 0.000000, te_loss = 0.002118\n",
            "grad_step = 003570, tr_loss = 0.000000, te_loss = 0.002118\n",
            "grad_step = 003600, tr_loss = 0.000000, te_loss = 0.002118\n",
            "grad_step = 003630, tr_loss = 0.000000, te_loss = 0.002384\n",
            "grad_step = 003660, tr_loss = 0.000000, te_loss = 0.002384\n",
            "grad_step = 003690, tr_loss = 0.000000, te_loss = 0.002384\n",
            "grad_step = 003720, tr_loss = 0.000000, te_loss = 0.002386\n",
            "grad_step = 003750, tr_loss = 0.000000, te_loss = 0.002386\n",
            "grad_step = 003780, tr_loss = 0.000003, te_loss = 0.002386\n",
            "grad_step = 003810, tr_loss = 0.000038, te_loss = 0.002325\n",
            "grad_step = 003840, tr_loss = 0.000001, te_loss = 0.002325\n",
            "grad_step = 003870, tr_loss = 0.000000, te_loss = 0.002325\n",
            "grad_step = 003900, tr_loss = 0.000000, te_loss = 0.002325\n",
            "grad_step = 003930, tr_loss = 0.000000, te_loss = 0.002396\n",
            "grad_step = 003960, tr_loss = 0.000000, te_loss = 0.002396\n",
            "grad_step = 003990, tr_loss = 0.000000, te_loss = 0.002396\n",
            "grad_step = 004020, tr_loss = 0.000549, te_loss = 0.002376\n",
            "grad_step = 004050, tr_loss = 0.000012, te_loss = 0.002376\n",
            "grad_step = 004080, tr_loss = 0.000001, te_loss = 0.002376\n",
            "grad_step = 004110, tr_loss = 0.000000, te_loss = 0.002490\n",
            "grad_step = 004140, tr_loss = 0.000000, te_loss = 0.002490\n",
            "grad_step = 004170, tr_loss = 0.000000, te_loss = 0.002490\n",
            "grad_step = 004200, tr_loss = 0.000000, te_loss = 0.002490\n",
            "grad_step = 004230, tr_loss = 0.000000, te_loss = 0.002496\n",
            "grad_step = 004260, tr_loss = 0.000000, te_loss = 0.002496\n",
            "grad_step = 004290, tr_loss = 0.000433, te_loss = 0.002496\n",
            "grad_step = 004320, tr_loss = 0.000008, te_loss = 0.002524\n",
            "grad_step = 004350, tr_loss = 0.000001, te_loss = 0.002524\n",
            "grad_step = 004380, tr_loss = 0.000000, te_loss = 0.002524\n",
            "grad_step = 004410, tr_loss = 0.000000, te_loss = 0.002552\n",
            "grad_step = 004440, tr_loss = 0.000000, te_loss = 0.002552\n",
            "grad_step = 004470, tr_loss = 0.000000, te_loss = 0.002552\n",
            "grad_step = 004500, tr_loss = 0.000003, te_loss = 0.002552\n",
            "grad_step = 004530, tr_loss = 0.000059, te_loss = 0.002479\n",
            "grad_step = 004560, tr_loss = 0.000001, te_loss = 0.002479\n",
            "grad_step = 004590, tr_loss = 0.000000, te_loss = 0.002479\n",
            "grad_step = 004620, tr_loss = 0.000000, te_loss = 0.002603\n",
            "grad_step = 004650, tr_loss = 0.000000, te_loss = 0.002603\n",
            "grad_step = 004680, tr_loss = 0.000262, te_loss = 0.002603\n",
            "grad_step = 004710, tr_loss = 0.000005, te_loss = 0.002787\n",
            "grad_step = 004740, tr_loss = 0.000001, te_loss = 0.002787\n",
            "grad_step = 004770, tr_loss = 0.000000, te_loss = 0.002787\n",
            "grad_step = 004800, tr_loss = 0.000000, te_loss = 0.002787\n",
            "grad_step = 004830, tr_loss = 0.000000, te_loss = 0.002674\n",
            "grad_step = 004860, tr_loss = 0.000000, te_loss = 0.002674\n",
            "grad_step = 004890, tr_loss = 0.000000, te_loss = 0.002674\n",
            "grad_step = 004920, tr_loss = 0.000000, te_loss = 0.002674\n",
            "grad_step = 004950, tr_loss = 0.000053, te_loss = 0.002674\n",
            "grad_step = 004980, tr_loss = 0.000002, te_loss = 0.002674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "forecast"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J3z2k9V2fU2",
        "outputId": "8cb93c46-4650-41aa-f61e-10deaac8bebb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[60.502777, 60.293   , 60.192764],\n",
              "       [64.08282 , 65.88086 , 67.36658 ],\n",
              "       [62.412285, 61.48633 , 60.982906],\n",
              "       [60.106346, 59.89401 , 59.53258 ],\n",
              "       [57.56158 , 57.855236, 58.045753],\n",
              "       [52.028984, 49.208984, 47.187572]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}